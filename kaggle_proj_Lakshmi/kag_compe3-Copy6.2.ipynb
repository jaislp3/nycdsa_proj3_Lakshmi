{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits username hardcore metallica ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matches background colour im seemingly stuck t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0  explanation edits username hardcore metallica ...\n",
       "1  matches background colour im seemingly stuck t...\n",
       "2  hey man im really trying edit war guy constant...\n",
       "3  make real suggestions improvement wondered sec...\n",
       "4                sir hero chance remember page thats"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_text = pd.read_csv('imptext.csv')\n",
    "imp_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('F:/notebook_working/kaggle_compe/train.csv').fillna('No data')\n",
    "test = pd.read_csv('F:/notebook_working/kaggle_compe/test.csv').fillna('No data')\n",
    "\n",
    "#train.id = train.id.astype('str')\n",
    "#train.comment_text = train.comment_text.astype('str')\n",
    "\n",
    "#test.id = test.id.astype('str')\n",
    "#test.comment_text = test.comment_text.astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train[['id', 'comment_text']]\n",
    "test_text = test[['id', 'comment_text']]\n",
    "combined_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 2)\n",
      "(153164, 2)\n",
      "id                                               fff46fc426af1f9a\n",
      "comment_text    \"\\nAnd ... I really don't think you understand...\n",
      "Name: 159570, dtype: object\n",
      "id                                               00001cee341fdb12\n",
      "comment_text    Yo bitch Ja Rule is more succesful then you'll...\n",
      "Name: 0, dtype: object\n",
      "id                                               fff46fc426af1f9a\n",
      "comment_text      really think understand came idea bad right ...\n",
      "Name: 159570, dtype: object\n",
      "id                                               00001cee341fdb12\n",
      "comment_text    yo bitch ja rule succesful ever whats hating s...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print train_text.shape\n",
    "print test_text.shape\n",
    "print train_text.iloc[train_text.shape[0]-1, ]\n",
    "print test_text.iloc[0, ]\n",
    "print combined_text.iloc[train_text.shape[0]-1,]\n",
    "print combined_text.iloc[train_text.shape[0],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text.shape\n",
    "#combined_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_text.comment.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = imp_text.loc[imp_text.comment.isna(), ]\n",
    "missing_index = list(missing.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[241L, 258L, 627L, 1050L, 1177L]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_text.iloc[missing_index, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont use errors='ignore'\n",
    "combined_text.comment_text = map(lambda x:unicode(x, 'utf-8'), combined_text.comment_text)\n",
    "#combined_text = map(lambda x:unicode(x, 'utf-8'), combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'i', u'me', u'my', u'myself', u'we', u'our', u'ours',\n",
       "       u'ourselves', u'you', u\"you're\", u\"you've\", u\"you'll\", u\"you'd\",\n",
       "       u'your', u'yours', u'yourself', u'yourselves', u'he', u'him',\n",
       "       u'his', u'himself', u'she', u\"she's\", u'her', u'hers', u'herself',\n",
       "       u'it', u\"it's\", u'its', u'itself', u'they', u'them', u'their',\n",
       "       u'theirs', u'themselves', u'what', u'which', u'who', u'whom',\n",
       "       u'this', u'that', u\"that'll\", u'these', u'those', u'am', u'is',\n",
       "       u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has',\n",
       "       u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an',\n",
       "       u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until',\n",
       "       u'while', u'of', u'at', u'by', u'for', u'with', u'about',\n",
       "       u'against', u'between', u'into', u'through', u'during', u'before',\n",
       "       u'after', u'above', u'below', u'to', u'from', u'up', u'down',\n",
       "       u'in', u'out', u'on', u'off', u'over', u'under', u'again',\n",
       "       u'further', u'then', u'once', u'here', u'there', u'when', u'where',\n",
       "       u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more',\n",
       "       u'most', u'other', u'some', u'such', u'no', u'nor', u'not',\n",
       "       u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's',\n",
       "       u't', u'can', u'will', u'just', u'don', u\"don't\", u'should',\n",
       "       u\"should've\", u'now', u'd', u'll', u'm', u'o', u're', u've', u'y',\n",
       "       u'ain', u'aren', u\"aren't\", u'couldn', u\"couldn't\", u'didn',\n",
       "       u\"didn't\", u'doesn', u\"doesn't\", u'hadn', u\"hadn't\", u'hasn',\n",
       "       u\"hasn't\", u'haven', u\"haven't\", u'isn', u\"isn't\", u'ma',\n",
       "       u'mightn', u\"mightn't\", u'mustn', u\"mustn't\", u'needn', u\"needn't\",\n",
       "       u'shan', u\"shan't\", u'shouldn', u\"shouldn't\", u'wasn', u\"wasn't\",\n",
       "       u'weren', u\"weren't\", u'won', u\"won't\", u'wouldn', u\"wouldn't\"],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#extracting the stopwords from nltk library\n",
    "sw = stopwords.words('english')\n",
    "# displaying the stopwords\n",
    "np.array(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(text):\n",
    "    '''a function for removing the stopword'''\n",
    "# removing the stop words and lowercasing the selected words\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    # joining the list of words with space separator\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d'aww! matches background colour i'm seemingly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man, i'm really trying edit war. guy const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" can't make real suggestions improvement - wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you, sir, hero. chance remember page that's on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\" congratulations well, use tools well. 路 talk \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>vandalism matt shirvington article reverted. p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry word 'nonsense' offensive you. anyway, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  0000997932d777bf  explanation edits made username hardcore metal...\n",
       "1  000103f0d9cfb60f  d'aww! matches background colour i'm seemingly...\n",
       "2  000113f07ec002fd  hey man, i'm really trying edit war. guy const...\n",
       "3  0001b41b1c6bb37e  \" can't make real suggestions improvement - wo...\n",
       "4  0001d958c54c6e35    you, sir, hero. chance remember page that's on?\n",
       "5  00025465d4725e87   \" congratulations well, use tools well. 路 talk \"\n",
       "6  0002bcb3da6cb337                        cocksucker piss around work\n",
       "7  00031b1e95af7921  vandalism matt shirvington article reverted. p...\n",
       "8  00037261f536c51d  sorry word 'nonsense' offensive you. anyway, i...\n",
       "9  00040093b2687caa               alignment subject contrary dulithgow"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text['comment_text'] = combined_text['comment_text'].apply(stopwords)\n",
    "combined_text.head(10)\n",
    "#combined_text = map(stopwords, combined_text)\n",
    "#combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>cant make real suggestions improvement - wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you sir hero chance remember page thats on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>congratulations well use tools well 路 talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry word nonsense offensive you anyway im in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  0000997932d777bf  explanation edits made username hardcore metal...\n",
       "1  000103f0d9cfb60f  daww matches background colour im seemingly st...\n",
       "2  000113f07ec002fd  hey man im really trying edit war guy constant...\n",
       "3  0001b41b1c6bb37e   cant make real suggestions improvement - wond...\n",
       "4  0001d958c54c6e35         you sir hero chance remember page thats on\n",
       "5  00025465d4725e87        congratulations well use tools well 路 talk \n",
       "6  0002bcb3da6cb337                        cocksucker piss around work\n",
       "7  00031b1e95af7921  vandalism matt shirvington article reverted pl...\n",
       "8  00037261f536c51d  sorry word nonsense offensive you anyway im in...\n",
       "9  00040093b2687caa               alignment subject contrary dulithgow"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PunctuationToRemove = [\".\", \",\", \":\", \";\", \"!\" ,\"?\", \"&\", \"\\\"\", \"\\'\", \"~\", \"\\\\\", \"=\"]\n",
    "def remove_punctuation(text):\n",
    "    '''a function for removing punctuation'''\n",
    "    for char in PunctuationToRemove:\n",
    "        text = text.replace(char,\"\")\n",
    "    return text\n",
    "combined_text['comment_text'] = combined_text['comment_text'].apply(remove_punctuation)\n",
    "combined_text.head(10)\n",
    "#combined_text = map(remove_punctuation, combined_text)\n",
    "#combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_values = list(combined_text.iloc[missing_index, 1])\n",
    "#missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_text1 = imp_text.copy()\n",
    "imp_text1.iloc[missing_index, 0] = missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_text1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp_text1.to_csv('F:/notebook_working/imptext1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = imp_text1.comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = list(all_text)\n",
    "type(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571\n",
      "153164\n"
     ]
    }
   ],
   "source": [
    "train_text1 = all_text[:train_text.shape[0]]\n",
    "test_text1 = all_text[train_text.shape[0]:len(all_text)]\n",
    "print len(train_text1)\n",
    "print len(test_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_text1[len(train_text1)-1]\n",
    "#test_text1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25393 tokens in Comment_text if we use word\n"
     ]
    }
   ],
   "source": [
    "#whole data\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    encoding='utf-8',\n",
    "    lowercase=True,\n",
    "    #min_df=0.00001,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    #use_idf=1, smooth_idf=1,\n",
    "    max_features=None)\n",
    "\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text.comment_text)\n",
    "test_word_features = word_vectorizer.transform(test_text.comment_text)\n",
    "\n",
    "msg = \"There are {} tokens in Comment_text if we use word\"\n",
    "print(msg.format(len(word_vectorizer.get_feature_names())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 854 tokens in Comment_text if we use char\n"
     ]
    }
   ],
   "source": [
    "#dont run\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    #norm=None,\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    min_df = 0.00001,\n",
    "    ngram_range=(1,1)) \n",
    "    #non_negative=True,\n",
    "    \n",
    "    #max_features=10000)\n",
    "    \n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text1)\n",
    "test_char_features = char_vectorizer.transform(test_text1)\n",
    "\n",
    "msg = \"There are {} tokens in Comment_text if we use char\"\n",
    "print(msg.format(len(char_vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.969050842841\n",
      "CV score for class severe_toxic is 0.985685426799\n",
      "CV score for class obscene is 0.98543180024\n",
      "CV score for class threat is 0.978245169467\n",
      "CV score for class insult is 0.976033206562\n",
      "CV score for class identity_hate is 0.971681682638\n",
      "Total CV score is 0.977688021425\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(train_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_word_features, train_target)\n",
    "    #submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "#submission.to_csv('F:\\impwordssub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.92123216964\n",
      "CV score for class severe_toxic is 0.91847880705\n",
      "CV score for class obscene is 0.921219071701\n",
      "CV score for class threat is 0.864997542019\n",
      "CV score for class insult is 0.916600110339\n",
      "CV score for class identity_hate is 0.906683340467\n",
      "Total CV score is 0.908201840203\n"
     ]
    }
   ],
   "source": [
    "#train_features = hstack([train_char_features, train_word_features])\n",
    "#test_features = hstack([test_char_features, test_word_features])\n",
    "\n",
    "\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(train_word_features, train_target, test_size=0.3, random_state=42)\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, X_valid, y_valid, cv=5, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    #submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
